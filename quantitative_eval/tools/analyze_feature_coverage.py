#!/usr/bin/env python3
"""
è¯¦ç»†çš„åŠŸèƒ½è¦†ç›–åˆ†æ
å¯¹æ¯”src/ä¸‹çš„åŸå§‹åŠŸèƒ½ä¸ç°ä»£åŒ–ç³»ç»Ÿçš„åŠŸèƒ½è¦†ç›–æƒ…å†µ
"""

import os
import ast
import inspect
from typing import Dict, List, Any

def analyze_file_functions(file_path: str) -> Dict[str, Any]:
    """åˆ†æPythonæ–‡ä»¶ä¸­çš„å‡½æ•°å’Œç±»"""
    result = {
        "file": file_path,
        "functions": [],
        "classes": [],
        "imports": [],
        "main_purpose": "",
        "key_features": []
    }

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # è§£æAST
        tree = ast.parse(content)

        # æå–å‡½æ•°
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                result["functions"].append({
                    "name": node.name,
                    "line": node.lineno,
                    "args": [arg.arg for arg in node.args.args]
                })
            elif isinstance(node, ast.ClassDef):
                result["classes"].append({
                    "name": node.name,
                    "line": node.lineno
                })
            elif isinstance(node, ast.Import):
                for alias in node.names:
                    result["imports"].append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    result["imports"].append(node.module)

        # åˆ†æä¸»è¦ç”¨é€”ï¼ˆé€šè¿‡æ³¨é‡Šå’Œå‡½æ•°åï¼‰
        if "whisper" in content or "sounddevice" in content:
            result["key_features"].append("è¯­éŸ³å¤„ç†")
        if "Falcon" in content or "falcon" in content:
            result["key_features"].append("Falconæ¨¡å‹")
        if "pipeline" in content and "transformers" in content:
            result["key_features"].append("æ–‡æœ¬ç”Ÿæˆ")
        if "FaissSearcher" in content or "LuceneSearcher" in content:
            result["key_features"].append("æ£€ç´¢åŠŸèƒ½")
        if "lambda" in file_path:
            result["key_features"].append("AWS Lambda")
        if "eval" in file_path:
            result["key_features"].append("è¯„ä¼°åŠŸèƒ½")

    except Exception as e:
        result["error"] = str(e)

    return result

def analyze_src_structure():
    """åˆ†æsrcæ–‡ä»¶å¤¹ç»“æ„å’ŒåŠŸèƒ½"""

    src_analysis = {}

    # å®šä¹‰srcä¸‹çš„ä¸»è¦æ–‡ä»¶
    src_files = [
        "src/retrieval/RAG_SYSTEM.py",
        "src/retrieval/RAG_SYSTEM_BM25.py",
        "src/retrieval/RAG_Voice_Demo.py",
        "src/retrieval/search.py",
        "src/retrieval/eval.py",
        "src/retrieval/build_index.py",
        "src/retrieval/data.py",
        "src/retrieval/helloworld.py",
        "src/nlg/falcon_gen.py",
        "src/nlg/eval.py",
        "src/intent-based/lambda/lambda_function.py",
        "src/intent-based/lambda/utils.py"
    ]

    print("=== åŸå§‹srcç³»ç»ŸåŠŸèƒ½åˆ†æ ===")

    for file_path in src_files:
        if os.path.exists(file_path):
            analysis = analyze_file_functions(file_path)
            src_analysis[file_path] = analysis

            print(f"\nğŸ“ {file_path}:")
            if analysis.get("key_features"):
                print(f"   æ ¸å¿ƒåŠŸèƒ½: {', '.join(analysis['key_features'])}")
            print(f"   å‡½æ•°æ•°é‡: {len(analysis['functions'])}")
            print(f"   ç±»æ•°é‡: {len(analysis['classes'])}")

            # æ˜¾ç¤ºå…³é”®å‡½æ•°
            key_functions = [f for f in analysis['functions'] if not f['name'].startswith('_')][:5]
            if key_functions:
                print(f"   å…³é”®å‡½æ•°: {', '.join([f['name'] for f in key_functions])}")

    return src_analysis

def compare_with_modern_system():
    """å¯¹æ¯”ç°ä»£åŒ–ç³»ç»Ÿçš„åŠŸèƒ½è¦†ç›–"""

    print(f"\n=== åŠŸèƒ½è¦†ç›–å¯¹æ¯”åˆ†æ ===")

    # å®šä¹‰åŠŸèƒ½æ˜ å°„å…³ç³»
    feature_mapping = {
        "src/retrieval/RAG_SYSTEM.py": {
            "modern_equivalent": "modern_voice_rag_system.py",
            "coverage_status": "éœ€è¦éªŒè¯",
            "original_features": [
                "å®Œæ•´è¯­éŸ³RAGæµç¨‹",
                "è¯­éŸ³å½•åˆ¶ (sounddevice)",
                "è¯­éŸ³è½¬æ–‡å­— (whisper)",
                "DPRå¯†é›†æ£€ç´¢",
                "Falconæ–‡æœ¬ç”Ÿæˆ",
                "æ–‡å­—è½¬è¯­éŸ³ (gTTS)",
                "éŸ³é¢‘æ’­æ”¾ (pygame)",
                "æ—¥å¿—è®°å½•",
                "å›è°ƒå‡½æ•°å¤„ç†"
            ]
        },
        "src/retrieval/RAG_SYSTEM_BM25.py": {
            "modern_equivalent": "modern_voice_rag_system.py + modern_rag_system.py (BM25)",
            "coverage_status": "éœ€è¦éªŒè¯",
            "original_features": [
                "BM25ç‰ˆæœ¬è¯­éŸ³RAG",
                "ä¼ ç»Ÿå…³é”®è¯æ£€ç´¢"
            ]
        },
        "src/retrieval/search.py": {
            "modern_equivalent": "modern_faiss_retrieval.py + modern_rag_system.py",
            "coverage_status": "å·²è¦†ç›–",
            "original_features": [
                "DPRå¯†é›†æ£€ç´¢",
                "BM25æ£€ç´¢",
                "TRECæ ¼å¼è¾“å‡º",
                "æ‰¹é‡æŸ¥è¯¢å¤„ç†"
            ]
        },
        "src/retrieval/eval.py": {
            "modern_equivalent": "final_evaluation.py",
            "coverage_status": "å·²è¦†ç›–",
            "original_features": [
                "æ£€ç´¢æ€§èƒ½è¯„ä¼°",
                "RANXè¯„ä¼°å·¥å…·",
                "TRECè¯„ä¼°"
            ]
        },
        "src/retrieval/build_index.py": {
            "modern_equivalent": "modern_faiss_retrieval.py (build_indexæ–¹æ³•)",
            "coverage_status": "å·²è¦†ç›–",
            "original_features": [
                "FAISSç´¢å¼•æ„å»º"
            ]
        },
        "src/nlg/falcon_gen.py": {
            "modern_equivalent": "modern_rag_system.py (_generate_with_falconæ–¹æ³•)",
            "coverage_status": "å·²è¦†ç›–",
            "original_features": [
                "Falcon-7Bæ¨¡å‹åŠ è½½",
                "æ–‡æœ¬ç”Ÿæˆpipeline",
                "å¤šç§ç”Ÿæˆå‡½æ•°å˜ä½“",
                "ç”Ÿæˆå‚æ•°é…ç½®"
            ]
        },
        "src/nlg/eval.py": {
            "modern_equivalent": "final_evaluation.py",
            "coverage_status": "å·²è¦†ç›–",
            "original_features": [
                "ROUGEè¯„ä¼°",
                "BERTScoreè¯„ä¼°",
                "æ–‡æœ¬ç”Ÿæˆè´¨é‡è¯„ä¼°"
            ]
        },
        "src/intent-based/lambda/lambda_function.py": {
            "modern_equivalent": "src/intent-based/lambda/lambda_function_complete.py",
            "coverage_status": "å·²å‡çº§",
            "original_features": [
                "40+ä¸ªRMITæ„å›¾å¤„ç†å™¨",
                "AWS Lambdaå¤„ç†",
                "Alexa Skills Kité›†æˆ"
            ]
        }
    }

    coverage_summary = {
        "å®Œå…¨è¦†ç›–": [],
        "éƒ¨åˆ†è¦†ç›–": [],
        "éœ€è¦å¢å¼º": [],
        "ç¼ºå¤±åŠŸèƒ½": []
    }

    for src_file, mapping in feature_mapping.items():
        print(f"\nğŸ” {src_file}")
        print(f"   ç°ä»£å¯¹åº”: {mapping['modern_equivalent']}")
        print(f"   çŠ¶æ€: {mapping['coverage_status']}")
        print(f"   åŸåŠŸèƒ½:")
        for feature in mapping['original_features']:
            print(f"     - {feature}")

        # åˆ†ç±»
        if mapping['coverage_status'] == "å·²è¦†ç›–":
            coverage_summary["å®Œå…¨è¦†ç›–"].append(src_file)
        elif mapping['coverage_status'] == "éƒ¨åˆ†è¦†ç›–":
            coverage_summary["éƒ¨åˆ†è¦†ç›–"].append(src_file)
        elif mapping['coverage_status'] == "éœ€è¦éªŒè¯":
            coverage_summary["éœ€è¦å¢å¼º"].append(src_file)
        else:
            coverage_summary["ç¼ºå¤±åŠŸèƒ½"].append(src_file)

    return coverage_summary

def detailed_falcon_comparison():
    """è¯¦ç»†å¯¹æ¯”FalconåŠŸèƒ½"""

    print(f"\n=== FalconåŠŸèƒ½è¯¦ç»†å¯¹æ¯” ===")

    print("ğŸ“Š src/nlg/falcon_gen.py åŸå§‹åŠŸèƒ½:")

    try:
        with open("src/nlg/falcon_gen.py", 'r', encoding='utf-8') as f:
            content = f.read()

        # æå–å‡½æ•°å®šä¹‰
        import re
        functions = re.findall(r'def\s+(\w+)\s*\([^)]*\):', content)
        print(f"   åŸå§‹å‡½æ•°: {', '.join(functions)}")

        # æ£€æŸ¥å…³é”®é…ç½®
        if "gen_answer_base1_v1" in content:
            print("   âœ… åŸºç¡€ç”Ÿæˆå‡½æ•°")
        if "pipeline" in content:
            print("   âœ… Transformers pipeline")
        if "max_new_tokens" in content:
            print("   âœ… ç”Ÿæˆå‚æ•°é…ç½®")
        if "temperature" in content:
            print("   âœ… æ¸©åº¦å‚æ•°")

    except FileNotFoundError:
        print("   âŒ åŸæ–‡ä»¶ä¸å­˜åœ¨")

    print(f"\nğŸ“Š modern_rag_system.py ç°ä»£åŠŸèƒ½:")

    try:
        with open("modern_rag_system.py", 'r', encoding='utf-8') as f:
            content = f.read()

        if "_generate_with_falcon" in content:
            print("   âœ… Falconç”Ÿæˆæ–¹æ³•")
        if "AutoModelForCausalLM" in content:
            print("   âœ… æ¨¡å‹åŠ è½½")
        if "generate(" in content:
            print("   âœ… ç”Ÿæˆè°ƒç”¨")
        if "temperature" in content:
            print("   âœ… ç”Ÿæˆå‚æ•°")

        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘åŸå§‹åŠŸèƒ½
        missing_features = []

        if "_gen_answer_base1_v1" not in content:
            missing_features.append("åŸå§‹ç”Ÿæˆå‡½æ•°å˜ä½“")
        if "Generate an answer to be synthesized" not in content:
            missing_features.append("åŸå§‹æç¤ºæ¨¡æ¿")

        if missing_features:
            print("   âš ï¸  ç¼ºå°‘åŠŸèƒ½:")
            for feature in missing_features:
                print(f"     - {feature}")
        else:
            print("   âœ… æ‰€æœ‰åŸå§‹åŠŸèƒ½å·²å®Œæ•´é›†æˆ")

    except FileNotFoundError:
        print("   âŒ ç°ä»£æ–‡ä»¶ä¸å­˜åœ¨")

def identify_enhancement_needs():
    """è¯†åˆ«éœ€è¦å¢å¼ºçš„åŠŸèƒ½"""

    print(f"\n=== åŠŸèƒ½å¢å¼ºéœ€æ±‚åˆ†æ ===")

    enhancement_needs = [
        {
            "area": "Falconæ–‡æœ¬ç”Ÿæˆ",
            "issue": "modern_rag_system.pyçš„Falconé›†æˆå¯èƒ½ä¸å®Œæ•´",
            "action": "å¢å¼º_generate_with_falconæ–¹æ³•ï¼ŒåŒ…å«åŸå§‹çš„æ‰€æœ‰ç”Ÿæˆå˜ä½“",
            "priority": "é«˜"
        },
        {
            "area": "è¯­éŸ³RAGç³»ç»Ÿ",
            "issue": "éœ€è¦éªŒè¯modern_voice_rag_system.pyæ˜¯å¦å®Œå…¨æ›¿ä»£RAG_SYSTEM.py",
            "action": "è¯¦ç»†å¯¹æ¯”è¯­éŸ³æµç¨‹çš„æ¯ä¸ªæ­¥éª¤",
            "priority": "é«˜"
        },
        {
            "area": "è¯„ä¼°åŠŸèƒ½",
            "issue": "src/nlg/eval.pyçš„ROUGEå’ŒBERTScoreè¯„ä¼°",
            "action": "åœ¨final_evaluation.pyä¸­æ·»åŠ æ–‡æœ¬ç”Ÿæˆè´¨é‡è¯„ä¼°",
            "priority": "ä¸­"
        },
        {
            "area": "ç´¢å¼•æ„å»º",
            "issue": "build_index.pyçš„æ‰€æœ‰åŠŸèƒ½æ˜¯å¦å®Œå…¨è¿ç§»",
            "action": "éªŒè¯modern_faiss_retrieval.pyçš„ç´¢å¼•æ„å»ºå®Œæ•´æ€§",
            "priority": "ä¸­"
        },
        {
            "area": "æ•°æ®å¤„ç†",
            "issue": "src/retrieval/data.pyçš„æ•°æ®å¤„ç†å·¥å…·",
            "action": "æ£€æŸ¥æ˜¯å¦éœ€è¦ç‹¬ç«‹çš„æ•°æ®å¤„ç†æ¨¡å—",
            "priority": "ä½"
        }
    ]

    for need in enhancement_needs:
        print(f"\nğŸ”§ {need['area']} ({need['priority']}ä¼˜å…ˆçº§)")
        print(f"   é—®é¢˜: {need['issue']}")
        print(f"   è¡ŒåŠ¨: {need['action']}")

    return enhancement_needs

def main():
    """ä¸»åˆ†æå‡½æ•°"""

    print("ğŸ” Romeo & Juliet RAGç³»ç»Ÿ - åŠŸèƒ½è¦†ç›–å®Œæ•´æ€§åˆ†æ")
    print("=" * 70)

    # åˆ†æsrcç»“æ„
    src_analysis = analyze_src_structure()

    # åŠŸèƒ½è¦†ç›–å¯¹æ¯”
    coverage_summary = compare_with_modern_system()

    # Falconè¯¦ç»†å¯¹æ¯”
    detailed_falcon_comparison()

    # å¢å¼ºéœ€æ±‚
    enhancement_needs = identify_enhancement_needs()

    # æ€»ç»“
    print(f"\n" + "=" * 70)
    print(f"ğŸ“‹ åˆ†ææ€»ç»“:")

    for category, files in coverage_summary.items():
        if files:
            print(f"\n{category}: {len(files)} ä¸ªæ–‡ä»¶")
            for file in files:
                print(f"  - {file}")

    print(f"\nğŸ¯ å»ºè®®çš„ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
    print(f"1. å¢å¼ºFalconé›†æˆåŠŸèƒ½ (é«˜ä¼˜å…ˆçº§)")
    print(f"2. éªŒè¯è¯­éŸ³RAGå®Œæ•´æ€§ (é«˜ä¼˜å…ˆçº§)")
    print(f"3. è¡¥å……æ–‡æœ¬ç”Ÿæˆè¯„ä¼° (ä¸­ä¼˜å…ˆçº§)")
    print(f"4. å®Œå–„æ•°æ®å¤„ç†å·¥å…· (ä½ä¼˜å…ˆçº§)")

if __name__ == "__main__":
    main()