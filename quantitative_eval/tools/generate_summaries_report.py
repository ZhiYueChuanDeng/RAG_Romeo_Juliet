#!/usr/bin/env python3
"""
ä¸ºRomeo & Juliet RAGç³»ç»Ÿç”Ÿæˆsummariesè¯„ä¼°æŠ¥å‘Š
åŸºäºæ–°çš„è¯„ä¼°ç»“æœåˆ›å»ºç³»ç»Ÿæ€§èƒ½æ€»ç»“
"""

import os
import pandas as pd
import json
from pathlib import Path

def create_performance_summary():
    """åˆ›å»ºæ€§èƒ½æ€»ç»“æŠ¥å‘Š"""

    print("=== ç”ŸæˆRomeo & Juliet RAGç³»ç»Ÿæ€§èƒ½æ€»ç»“ ===")

    # è¯»å–trec_evalç»“æœ
    results_dir = "target/trec_eval_results"

    # æ–¹æ³•é…ç½®
    methods = {
        "FAISS Dense Retrieval": "romeo-juliet-faiss.txt",
        "BM25 Keyword Search": "romeo-juliet-bm25.txt",
        "Intent-based Retrieval": "romeo-juliet-intent.txt"
    }

    summary_data = []

    for method_name, result_file in methods.items():
        result_path = os.path.join(results_dir, result_file)

        if not os.path.exists(result_path):
            print(f"âš ï¸  ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {result_path}")
            continue

        print(f"å¤„ç†: {method_name}")

        # è¯»å–å¹³å‡æŒ‡æ ‡
        metrics = {}
        with open(result_path, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split('\t')
                if len(parts) >= 3 and parts[1] == "all":
                    metric_name = parts[0].strip()
                    value = float(parts[2])
                    metrics[metric_name] = value

        # æ·»åŠ åˆ°æ€»ç»“æ•°æ®
        summary_data.append({
            "Method": method_name,
            "MAP": metrics.get("map", 0.0),
            "NDCG": metrics.get("ndcg", 0.0),
            "P@5": metrics.get("P_5", 0.0),
            "P@10": metrics.get("P_10", 0.0),
            "P@20": metrics.get("P_20", 0.0),
            "Recall@5": metrics.get("recall_5", 0.0),
            "Recall@10": metrics.get("recall_10", 0.0),
            "Recall@20": metrics.get("recall_20", 0.0),
            "BPref": metrics.get("bpref", 0.0)
        })

    return summary_data

def generate_summary_csv(summary_data, output_path):
    """ç”ŸæˆCSVæ ¼å¼çš„æ€»ç»“æŠ¥å‘Š"""

    df = pd.DataFrame(summary_data)

    # ä¿å­˜åˆ°CSV
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    df.to_csv(output_path, index=False, float_format='%.4f')

    print(f"CSVæ€»ç»“æŠ¥å‘Šä¿å­˜åˆ°: {output_path}")

    # æ˜¾ç¤ºç»“æœ
    print("\nğŸ“Š æ€§èƒ½æ€»ç»“:")
    print(df.to_string(index=False, float_format='%.4f'))

    return df

def generate_markdown_report(summary_data, output_path):
    """ç”ŸæˆMarkdownæ ¼å¼çš„æ€»ç»“æŠ¥å‘Š"""

    df = pd.DataFrame(summary_data)

    markdown_content = """# Romeo & Juliet RAGç³»ç»Ÿè¯„ä¼°æŠ¥å‘Š

## ç³»ç»Ÿæ¦‚è¿°

æœ¬æŠ¥å‘Šæ€»ç»“äº†Romeo & Juliet RAGç³»ç»Ÿä¸‰ç§æ£€ç´¢æ–¹æ³•çš„æ€§èƒ½è¡¨ç°ï¼š

1. **FAISS Dense Retrieval**: åŸºäºsentence-transformersçš„è¯­ä¹‰æ£€ç´¢
2. **BM25 Keyword Search**: åŸºäºå…³é”®è¯çš„ä¼ ç»Ÿæ£€ç´¢
3. **Intent-based Retrieval**: ç»“åˆæ„å›¾æ£€æµ‹çš„æ··åˆæ£€ç´¢

## è¯„ä¼°æ•°æ®é›†

- **æ–‡æ¡£é›†åˆ**: 160ä¸ªRomeo & Julietç›¸å…³æ®µè½
- **æŸ¥è¯¢é›†åˆ**: 200ä¸ªé—®é¢˜ï¼ˆæ¶µç›–50ä¸ªä¸»é¢˜ï¼Œæ¯ä¸ªä¸»é¢˜4ä¸ªå˜ä½“é—®é¢˜ï¼‰
- **è¯„ä¼°æŒ‡æ ‡**: MAP, NDCG, Precision@K, Recall@K, BPref

## æ€§èƒ½ç»“æœ

"""

    # æ·»åŠ è¡¨æ ¼
    markdown_content += "| æ–¹æ³• | MAP | NDCG | P@5 | P@10 | P@20 | Recall@5 | Recall@10 | Recall@20 | BPref |\n"
    markdown_content += "|------|-----|------|-----|------|------|----------|-----------|-----------|-------|\n"

    for _, row in df.iterrows():
        markdown_content += f"| {row['Method']} | {row['MAP']:.4f} | {row['NDCG']:.4f} | {row['P@5']:.4f} | {row['P@10']:.4f} | {row['P@20']:.4f} | {row['Recall@5']:.4f} | {row['Recall@10']:.4f} | {row['Recall@20']:.4f} | {row['BPref']:.4f} |\n"

    # æ·»åŠ åˆ†æ
    best_method = df.loc[df['MAP'].idxmax(), 'Method']
    best_map = df['MAP'].max()

    markdown_content += f"""

## ä¸»è¦å‘ç°

### æœ€ä½³æ€§èƒ½æ–¹æ³•
**{best_method}** åœ¨MAPæŒ‡æ ‡ä¸Šè¡¨ç°æœ€ä½³ï¼Œè¾¾åˆ° **{best_map:.4f}**ã€‚

### æ–¹æ³•å¯¹æ¯”åˆ†æ

#### FAISS Dense Retrieval
- ä¼˜åŠ¿ï¼šåœ¨å¤§éƒ¨åˆ†è¯­ä¹‰ç›¸å…³æ€§æŒ‡æ ‡ä¸Šè¡¨ç°ä¼˜ç§€
- é€‚ç”¨åœºæ™¯ï¼šå¤æ‚çš„è¯­ä¹‰ç†è§£æŸ¥è¯¢

#### BM25 Keyword Search
- ä¼˜åŠ¿ï¼šè®¡ç®—æ•ˆç‡é«˜ï¼Œå¯¹å…³é”®è¯åŒ¹é…æ•æ„Ÿ
- é€‚ç”¨åœºæ™¯ï¼šç²¾ç¡®å…³é”®è¯æŸ¥è¯¢

#### Intent-based Retrieval
- ä¼˜åŠ¿ï¼šç»“åˆæ„å›¾ç†è§£ï¼Œå¹³è¡¡å‡†ç¡®æ€§å’Œå“åº”é€Ÿåº¦
- é€‚ç”¨åœºæ™¯ï¼šå¯¹è¯å¼é—®ç­”ç³»ç»Ÿ

## ç³»ç»Ÿæ–‡ä»¶ç»“æ„

```
target/
â”œâ”€â”€ runs/                    # TRECæ ¼å¼æ£€ç´¢ç»“æœ
â”‚   â”œâ”€â”€ romeo-juliet-faiss.txt
â”‚   â”œâ”€â”€ romeo-juliet-bm25.txt
â”‚   â””â”€â”€ romeo-juliet-intent.txt
â”œâ”€â”€ trec_eval_results/       # è¯„ä¼°ç»“æœ
â”‚   â”œâ”€â”€ romeo-juliet-faiss.txt/.tex
â”‚   â”œâ”€â”€ romeo-juliet-bm25.txt/.tex
â”‚   â””â”€â”€ romeo-juliet-intent.txt/.tex
â””â”€â”€ summaries/              # æ€§èƒ½æ€»ç»“æŠ¥å‘Š
    â”œâ”€â”€ romeo_juliet_performance_summary.csv
    â””â”€â”€ romeo_juliet_evaluation_report.md
```

## ç»“è®º

ç°ä»£åŒ–çš„Romeo & Juliet RAGç³»ç»ŸæˆåŠŸæ›¿ä»£äº†åŸå§‹RMIT FAQç³»ç»Ÿï¼Œåœ¨ä¿æŒé«˜ç²¾åº¦çš„åŒæ—¶æä¾›äº†æ›´å¥½çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚FAISSå¯†é›†æ£€ç´¢æ–¹æ³•åœ¨å¤§å¤šæ•°æŒ‡æ ‡ä¸Šè¡¨ç°æœ€ä½³ï¼Œæ¨èä½œä¸ºä¸»è¦çš„æ£€ç´¢æ–¹æ³•ã€‚

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

    # ä¿å­˜Markdownæ–‡ä»¶
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(markdown_content)

    print(f"MarkdownæŠ¥å‘Šä¿å­˜åˆ°: {output_path}")

def clear_old_summaries():
    """æ¸…ç†æ—§çš„RMITç›¸å…³summaries"""

    summaries_dir = "target/summaries"

    if not os.path.exists(summaries_dir):
        print("summariesç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¸…ç†")
        return

    print("=== æ¸…ç†æ—§çš„RMIT summaries ===")

    # å¤‡ä»½æ—§æ–‡ä»¶
    backup_dir = "target/summaries_backup_rmit"
    if os.path.exists(summaries_dir):
        import shutil
        if os.path.exists(backup_dir):
            shutil.rmtree(backup_dir)
        shutil.copytree(summaries_dir, backup_dir)
        print(f"æ—§æ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_dir}")

    # æ¸…ç©ºç›®å½•
    import shutil
    if os.path.exists(summaries_dir):
        shutil.rmtree(summaries_dir)
    os.makedirs(summaries_dir, exist_ok=True)

    print("æ—§summarieså·²æ¸…ç†")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ­ ç”ŸæˆRomeo & Juliet RAGç³»ç»Ÿsummariesè¯„ä¼°æŠ¥å‘Š")
    print("=" * 55)

    # ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸­
    if not os.path.exists("target/trec_eval_results"):
        print("âŒ è¯·å…ˆè¿è¡Œtrec_evalè¯„ä¼°ç”Ÿæˆç»“æœ")
        return

    # æ¸…ç†æ—§summaries
    clear_old_summaries()

    # ç”Ÿæˆæ€§èƒ½æ€»ç»“
    summary_data = create_performance_summary()

    if not summary_data:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„è¯„ä¼°ç»“æœ")
        return

    # ç”ŸæˆCSVæŠ¥å‘Š
    csv_path = "target/summaries/romeo_juliet_performance_summary.csv"
    df = generate_summary_csv(summary_data, csv_path)

    # ç”ŸæˆMarkdownæŠ¥å‘Š
    md_path = "target/summaries/romeo_juliet_evaluation_report.md"
    generate_markdown_report(summary_data, md_path)

    print("\nâœ… summariesè¯„ä¼°æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")

    # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
    summaries_dir = "target/summaries"
    if os.path.exists(summaries_dir):
        print(f"\nğŸ“Š ç”Ÿæˆçš„summariesæ–‡ä»¶:")
        for filename in sorted(os.listdir(summaries_dir)):
            filepath = os.path.join(summaries_dir, filename)
            if os.path.isfile(filepath):
                file_size = os.path.getsize(filepath)
                print(f"  {filename}: {file_size} bytes")

if __name__ == "__main__":
    main()