#!/usr/bin/env python3
"""
ä¸ºRomeo & Juliet RAGç³»ç»Ÿç”Ÿæˆtrec_evalè¯„ä¼°ç»“æœ
ä½¿ç”¨æ–°ç”Ÿæˆçš„runsæ–‡ä»¶å’Œqrelsæ–‡ä»¶
"""

import os
import subprocess
import shutil
from pathlib import Path

def run_trec_eval(qrels_file: str, runs_file: str, output_file: str):
    """
    è¿è¡Œtrec_evalç¨‹åºç”Ÿæˆè¯„ä¼°ç»“æœ

    Args:
        qrels_file: ç›¸å…³æ€§åˆ¤æ–­æ–‡ä»¶è·¯å¾„
        runs_file: æ£€ç´¢ç»“æœæ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„
    """

    try:
        # æ£€æŸ¥trec_evalç¨‹åºæ˜¯å¦å­˜åœ¨
        trec_eval_cmd = "trec_eval"

        # è¿è¡Œtrec_evalå‘½ä»¤
        cmd = [trec_eval_cmd, "-m", "all_trec", qrels_file, runs_file]

        print(f"è¿è¡Œå‘½ä»¤: {' '.join(cmd)}")

        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            cwd=os.getcwd()
        )

        if result.returncode == 0:
            # ä¿å­˜ç»“æœ
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(result.stdout)
            print(f"è¯„ä¼°ç»“æœä¿å­˜åˆ°: {output_file}")
            return True
        else:
            print(f"trec_evalæ‰§è¡Œå¤±è´¥: {result.stderr}")
            return False

    except FileNotFoundError:
        print("âŒ trec_evalç¨‹åºæœªæ‰¾åˆ°ï¼Œè¯·ç¡®ä¿å·²å®‰è£…")
        print("æç¤ºï¼šå¯ä»¥ä» https://github.com/usnistgov/trec_eval ä¸‹è½½")
        return False
    except Exception as e:
        print(f"è¿è¡Œtrec_evalæ—¶å‡ºé”™: {e}")
        return False

def generate_tex_summary(txt_file: str, tex_file: str, method_name: str):
    """
    ç”ŸæˆLaTeXæ ¼å¼çš„è¯„ä¼°æ‘˜è¦

    Args:
        txt_file: trec_evalæ–‡æœ¬ç»“æœæ–‡ä»¶
        tex_file: è¾“å‡ºLaTeXæ–‡ä»¶è·¯å¾„
        method_name: æ–¹æ³•åç§°
    """

    if not os.path.exists(txt_file):
        print(f"âŒ æ–‡æœ¬ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {txt_file}")
        return

    # è¯»å–å…³é”®æŒ‡æ ‡
    metrics = {}

    with open(txt_file, 'r', encoding='utf-8') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 3 and parts[1] == "all":
                metric_name = parts[0]
                value = parts[2]
                metrics[metric_name] = value

    # ç”ŸæˆLaTeXè¡¨æ ¼
    latex_content = f"""% Romeo & Juliet RAG System - {method_name} è¯„ä¼°ç»“æœ
\\begin{{table}}[h]
\\centering
\\caption{{{method_name} æ–¹æ³•è¯„ä¼°ç»“æœ}}
\\begin{{tabular}}{{|l|c|}}
\\hline
æŒ‡æ ‡ & å€¼ \\\\
\\hline
"""

    # æ·»åŠ ä¸»è¦æŒ‡æ ‡
    key_metrics = {
        'map': 'MAP',
        'P_5': 'P@5',
        'P_10': 'P@10',
        'P_20': 'P@20',
        'recall_5': 'Recall@5',
        'recall_10': 'Recall@10',
        'recall_20': 'Recall@20',
        'ndcg': 'NDCG',
        'bpref': 'BPref'
    }

    for metric_key, metric_label in key_metrics.items():
        if metric_key in metrics:
            latex_content += f"{metric_label} & {metrics[metric_key]} \\\\\n"

    latex_content += """\\hline
\\end{tabular}
\\end{table}
"""

    # ä¿å­˜LaTeXæ–‡ä»¶
    os.makedirs(os.path.dirname(tex_file), exist_ok=True)
    with open(tex_file, 'w', encoding='utf-8') as f:
        f.write(latex_content)

    print(f"LaTeXæ‘˜è¦ä¿å­˜åˆ°: {tex_file}")

def clear_old_results():
    """æ¸…ç†æ—§çš„RMITç›¸å…³è¯„ä¼°ç»“æœ"""

    results_dir = "target/trec_eval_results"

    if not os.path.exists(results_dir):
        print("trec_eval_resultsç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¸…ç†")
        return

    print("=== æ¸…ç†æ—§çš„RMITè¯„ä¼°ç»“æœ ===")

    # å¤‡ä»½æ—§æ–‡ä»¶
    backup_dir = "target/trec_eval_results_backup_rmit"
    if os.path.exists(results_dir):
        if os.path.exists(backup_dir):
            shutil.rmtree(backup_dir)
        shutil.copytree(results_dir, backup_dir)
        print(f"æ—§æ–‡ä»¶å·²å¤‡ä»½åˆ°: {backup_dir}")

    # æ¸…ç©ºç›®å½•
    if os.path.exists(results_dir):
        shutil.rmtree(results_dir)
    os.makedirs(results_dir, exist_ok=True)

    print("æ—§è¯„ä¼°ç»“æœå·²æ¸…ç†")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ­ ç”ŸæˆRomeo & Juliet RAGç³»ç»Ÿtrec_evalè¯„ä¼°ç»“æœ")
    print("=" * 60)

    # ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•ä¸­
    if not os.path.exists("data/qrels.txt"):
        print("âŒ è¯·åœ¨quantitative_evalç›®å½•ä¸­è¿è¡Œæ­¤è„šæœ¬")
        return

    # æ¸…ç†æ—§ç»“æœ
    clear_old_results()

    # æ–‡ä»¶è·¯å¾„é…ç½®
    qrels_file = "data/qrels.txt"
    runs_configs = [
        {
            "runs_file": "target/runs/romeo-juliet-faiss.txt",
            "output_txt": "target/trec_eval_results/romeo-juliet-faiss.txt",
            "output_tex": "target/trec_eval_results/romeo-juliet-faiss.tex",
            "method_name": "FAISS Dense Retrieval"
        },
        {
            "runs_file": "target/runs/romeo-juliet-bm25.txt",
            "output_txt": "target/trec_eval_results/romeo-juliet-bm25.txt",
            "output_tex": "target/trec_eval_results/romeo-juliet-bm25.tex",
            "method_name": "BM25 Keyword Search"
        },
        {
            "runs_file": "target/runs/romeo-juliet-intent.txt",
            "output_txt": "target/trec_eval_results/romeo-juliet-intent.txt",
            "output_tex": "target/trec_eval_results/romeo-juliet-intent.tex",
            "method_name": "Intent-based Retrieval"
        }
    ]

    success_count = 0

    for config in runs_configs:
        runs_file = config["runs_file"]
        output_txt = config["output_txt"]
        output_tex = config["output_tex"]
        method_name = config["method_name"]

        print(f"\\n=== å¤„ç† {method_name} ===")

        if not os.path.exists(runs_file):
            print(f"âš ï¸  runsæ–‡ä»¶ä¸å­˜åœ¨: {runs_file}")
            continue

        # ç”Ÿæˆtrec_evalç»“æœ
        if run_trec_eval(qrels_file, runs_file, output_txt):
            # ç”ŸæˆLaTeXæ‘˜è¦
            generate_tex_summary(output_txt, output_tex, method_name)
            success_count += 1
        else:
            print(f"âŒ {method_name} è¯„ä¼°å¤±è´¥")

    print(f"\\nâœ… å®Œæˆï¼æˆåŠŸç”Ÿæˆäº† {success_count}/{len(runs_configs)} ä¸ªè¯„ä¼°ç»“æœ")

    # æ˜¾ç¤ºç»“æœæ–‡ä»¶
    results_dir = "target/trec_eval_results"
    if os.path.exists(results_dir):
        print(f"\\nğŸ“Š ç”Ÿæˆçš„è¯„ä¼°ç»“æœæ–‡ä»¶:")
        for filename in sorted(os.listdir(results_dir)):
            filepath = os.path.join(results_dir, filename)
            if os.path.isfile(filepath):
                file_size = os.path.getsize(filepath)
                print(f"  {filename}: {file_size} bytes")

    if success_count == 0:
        print("\\nğŸ’¡ æç¤ºï¼šå¦‚æœtrec_evalæœªå®‰è£…ï¼Œä½ å¯ä»¥ï¼š")
        print("  1. ä¸‹è½½å®‰è£…ï¼šhttps://github.com/usnistgov/trec_eval")
        print("  2. æˆ–ä½¿ç”¨pytrec_evalåŒ…ï¼špip install pytrec_eval")

if __name__ == "__main__":
    main()