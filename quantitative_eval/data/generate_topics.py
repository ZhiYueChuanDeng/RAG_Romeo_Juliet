import pandas as pd
import os
import csv
import re

def normalize_text(text):
    """æ ‡å‡†åŒ–æ–‡æœ¬ä»¥ä¾¿æ¯”è¾ƒï¼Œå»é™¤æ ‡ç‚¹ç¬¦å·å·®å¼‚"""
    # ç§»é™¤æ‰€æœ‰æ’‡å·
    text = text.replace("'", "")
    # æ ‡å‡†åŒ–å¼•å· - å°†æ‰€æœ‰å¼•å·ç±»å‹è½¬æ¢ä¸ºç®€å•çš„åŒå¼•å·
    text = text.replace('""', '"').replace('"', '"').replace('"', '"')
    # ç§»é™¤å¤šä½™ç©ºæ ¼
    text = ' '.join(text.split())
    return text.lower()

def replace_question_in_topics(q_txt_path, topics_csv_path, output_csv_path):
    """
    å°†Q.txtä¸­å¯¹åº”topicçš„é—®é¢˜æ›¿æ¢åˆ°topics.csvçš„questionåˆ—
    txtä¸­åºå·è¡Œå¯¹åº”csvçš„topicï¼Œåºå·è¡Œä¸‹çš„"- "å¼€å¤´è¡Œå¯¹åº”è¯¥topicçš„questionåˆ—è¡¨
    """
    # -------------------------- 1. è§£æQ.txtä¸ºtopic-é—®é¢˜åˆ—è¡¨å­—å…¸ --------------------------
    try:
        topic_questions = {}  # å­˜å‚¨{normalize_topic: [question1, question2, ...]}
        original_topics = {}  # å­˜å‚¨{normalize_topic: original_topic}
        current_topic = None
        current_questions = []

        with open(q_txt_path, 'r', encoding='UTF-8') as f:
            for line in f:
                line_stripped = line.strip()
                if not line_stripped:  # è·³è¿‡ç©ºè¡Œ
                    continue

                # åŒ¹é…åºå·è¡Œï¼ˆå¦‚"1. ..."ï¼‰
                seq_match = re.match(r'^\d+\. (.*)$', line_stripped)
                if seq_match:
                    # è‹¥å·²æœ‰å½“å‰topicï¼Œå…ˆå­˜å…¥å­—å…¸
                    if current_topic is not None:
                        normalized_topic = normalize_text(current_topic)
                        topic_questions[normalized_topic] = current_questions
                        original_topics[normalized_topic] = current_topic
                    # æ›´æ–°å½“å‰topicå’Œé—®é¢˜åˆ—è¡¨
                    current_topic = seq_match.group(1).strip()  # æå–åºå·åçš„å†…å®¹ä½œä¸ºtopic
                    current_questions = []
                # åŒ¹é…"- "å¼€å¤´çš„é—®é¢˜è¡Œ
                elif line_stripped.startswith('- '):
                    if current_topic is None:
                        raise ValueError("Q.txtæ ¼å¼é”™è¯¯ï¼šé—®é¢˜è¡Œ(- )å‡ºç°åœ¨ç¬¬ä¸€ä¸ªåºå·è¡Œä¹‹å‰")
                    question = line_stripped[2:].strip()  # å»é™¤"- "
                    current_questions.append(question)

        # ä¿å­˜æœ€åä¸€ä¸ªtopicçš„é—®é¢˜åˆ—è¡¨
        if current_topic is not None:
            normalized_topic = normalize_text(current_topic)
            topic_questions[normalized_topic] = current_questions
            original_topics[normalized_topic] = current_topic

        # éªŒè¯txtè§£æç»“æœ
        if not topic_questions:
            raise ValueError("Q.txtä¸­æœªè§£æåˆ°ä»»ä½•topicå’Œé—®é¢˜")
        print(f"âœ… æˆåŠŸè§£æQ.txtï¼šå…±{len(topic_questions)}ä¸ªtopicï¼Œé—®é¢˜æ•°é‡åˆ†å¸ƒï¼š{[len(q) for q in topic_questions.values()]}")

    except FileNotFoundError:
        print(f"âŒ æœªæ‰¾åˆ°Q.txtæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼š{q_txt_path}")
        return
    except Exception as e:
        print(f"âŒ è§£æQ.txtæ—¶å‡ºé”™ï¼š{str(e)}")
        return

    # -------------------------- 2. è¯»å–å¹¶éªŒè¯topics.csv --------------------------
    try:
        df = pd.read_csv(
            topics_csv_path,
            encoding='UTF-8',
            sep=',',
            quotechar='"',
            na_filter=False
        )

        # éªŒè¯å¿…éœ€åˆ—
        required_cols = ['topic_id', 'topic', 'question_id', 'question']
        if not all(col in df.columns for col in required_cols):
            raise ValueError(f"topics.csvç¼ºå°‘å¿…éœ€åˆ—ï¼Œéœ€åŒ…å«ï¼š{required_cols}")

        # æŒ‰topicåˆ†ç»„ï¼Œæ£€æŸ¥æ¯ä¸ªtopicçš„è¡Œæ•°
        topic_groups = df.groupby('topic').groups

        # åˆ›å»ºæ ‡å‡†åŒ–çš„topicæ˜ å°„
        csv_topic_mapping = {}  # {normalized_csv_topic: original_csv_topic}
        matched_topics = {}  # {original_csv_topic: normalized_txt_topic}

        for csv_topic in topic_groups:
            normalized_csv_topic = normalize_text(csv_topic)
            csv_topic_mapping[normalized_csv_topic] = csv_topic

            # æŸ¥æ‰¾åŒ¹é…çš„txt topic
            if normalized_csv_topic in topic_questions:
                matched_topics[csv_topic] = normalized_csv_topic
            else:
                # å°è¯•æ¨¡ç³ŠåŒ¹é…
                found_match = False
                for txt_normalized in topic_questions:
                    # ç®€å•çš„æ¨¡ç³ŠåŒ¹é…ï¼Œæ£€æŸ¥ä¸»è¦å•è¯æ˜¯å¦ç›¸åŒ
                    csv_words = set(normalized_csv_topic.split())
                    txt_words = set(txt_normalized.split())
                    # å¦‚æœ80%çš„å•è¯åŒ¹é…ï¼Œè®¤ä¸ºæ˜¯åŒä¸€ä¸ªtopic
                    if len(csv_words & txt_words) / max(len(csv_words), len(txt_words)) > 0.8:
                        matched_topics[csv_topic] = txt_normalized
                        print(f"ğŸ”— æ¨¡ç³ŠåŒ¹é…æˆåŠŸï¼šCSV '{csv_topic[:50]}...' â†” TXT '{original_topics[txt_normalized][:50]}...'")
                        found_match = True
                        break

                if not found_match:
                    print(f"âš ï¸  CSVä¸­çš„topicæœªæ‰¾åˆ°åŒ¹é…ï¼š{csv_topic}")
                    # ç»§ç»­å¤„ç†ï¼Œä½†è·³è¿‡è¿™ä¸ªtopic

        # æ£€æŸ¥æ¯ä¸ªåŒ¹é…topicçš„é—®é¢˜æ•°é‡
        for csv_topic, txt_normalized in matched_topics.items():
            csv_row_count = len(topic_groups[csv_topic])
            txt_question_count = len(topic_questions[txt_normalized])
            if csv_row_count != txt_question_count:
                print(f"âš ï¸  topic '{csv_topic[:30]}...' çš„é—®é¢˜æ•°é‡ä¸åŒ¹é…ï¼šcsvä¸­æœ‰{csv_row_count}è¡Œï¼Œtxtä¸­æœ‰{txt_question_count}ä¸ªé—®é¢˜")
                # è°ƒæ•´ä»¥è¾ƒå°çš„æ•°é‡ä¸ºå‡†
                min_count = min(csv_row_count, txt_question_count)
                print(f"    å°†ä½¿ç”¨å‰{min_count}ä¸ªé—®é¢˜è¿›è¡Œæ›¿æ¢")

        print(f"âœ… æˆåŠŸè¯»å–topics.csvï¼šå…±{len(df)}æ¡è®°å½•ï¼Œ{len(topic_groups)}ä¸ªtopicï¼Œå…¶ä¸­{len(matched_topics)}ä¸ªä¸Q.txtåŒ¹é…")

    except FileNotFoundError:
        print(f"âŒ æœªæ‰¾åˆ°topics.csvæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼š{topics_csv_path}")
        return
    except Exception as e:
        print(f"âŒ è¯»å–topics.csvæ—¶å‡ºé”™ï¼š{str(e)}")
        return

    # -------------------------- 3. æŒ‰topicæ›¿æ¢questionåˆ—å’Œtopicåˆ—å¹¶ä¿å­˜ --------------------------
    try:
        replaced_count = 0
        # éå†æ¯ä¸ªåŒ¹é…çš„topicï¼Œæ›¿æ¢å¯¹åº”çš„questionå’Œtopic
        for csv_topic, txt_normalized in matched_topics.items():
            indices = topic_groups[csv_topic]
            questions = topic_questions[txt_normalized]
            original_topic = original_topics[txt_normalized]  # è·å–Q.txtä¸­çš„åŸå§‹topicï¼ˆå¸¦æ’‡å·ï¼‰

            # æŒ‰ç´¢å¼•é¡ºåºæ›¿æ¢ï¼Œä½¿ç”¨è¾ƒå°çš„æ•°é‡
            max_replacements = min(len(indices), len(questions))
            for i in range(max_replacements):
                df.at[indices[i], 'question'] = questions[i]
                df.at[indices[i], 'topic'] = original_topic  # åŒæ—¶ä¿®å¤topicåˆ—
                replaced_count += 1

        # ä¿å­˜æ–‡ä»¶
        df.to_csv(
            output_csv_path,
            encoding='UTF-8',
            index=False,
            sep=',',
            quotechar='"',
            quoting=csv.QUOTE_ALL
        )

        print(f"ğŸ‰ æ›¿æ¢å®Œæˆï¼å…±æ›¿æ¢äº†{replaced_count}ä¸ªé—®é¢˜ï¼ŒåŒæ—¶ä¿®å¤äº†topicåˆ—çš„æ’‡å·é—®é¢˜")
        print(f"ğŸ’¾ æ–°æ–‡ä»¶å·²ä¿å­˜è‡³ï¼š{output_csv_path}")
        print("\nğŸ“Œ æ›¿æ¢åå‰5æ¡è®°å½•é¢„è§ˆï¼š")
        print(df.head()[['topic_id', 'topic', 'question_id', 'question']].to_string(index=False))

    except Exception as e:
        print(f"âŒ æ›¿æ¢æˆ–ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™ï¼š{str(e)}")
        return

# -------------------------- 4. é…ç½®è·¯å¾„å¹¶è¿è¡Œ --------------------------
if __name__ == "__main__":
    Q_TXT_PATH = "Q.txt"  # Q.txtæ–‡ä»¶è·¯å¾„
    TOPICS_CSV_PATH = "topics.csv"  # åŸå§‹topics.csvè·¯å¾„
    OUTPUT_CSV_PATH = "topics_updated.csv"  # æ›¿æ¢åè¾“å‡ºçš„CSVè·¯å¾„

    replace_question_in_topics(Q_TXT_PATH, TOPICS_CSV_PATH, OUTPUT_CSV_PATH)